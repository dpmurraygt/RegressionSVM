{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this modeling approach, we take a series of linear models, fine-tune them, and compare the forecast accuracies of the different models.  Additionally, although the approach for this assignment was supposed to be logistic regression and support vector machines (classification), our dataset better lends itself to a linear regression forecast.  Therefore, we will substitute logit with simple (naive baseline), multiple, and LASSO regression. We will then supplement with a support vector regression. While some approaches may be harder to replicate based on the rubric, we do our best to mimic the actions needed to tune a reasonable forecast in these models.  Additionally, we compare these approaches the a support vector regression and wind up using a stochastic gradient descent approach for comparison of different tunings of parameters.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcast Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to be within a reasonable range of the Zillow z-estimate forecast accuracy for this project. Of course, understanding that Zillow has much more user submitted, real-time, and proprietary data than we do, we would expect that it will be pretty hard to beat their forecast.  However, their median error rate for the Seattle area is about 5%.  Therefore, while this is a stretch goal, we will use this as our baseline to see if we are doing well.\n",
    "\n",
    "You can read more about Zillow's forecast accuracy here: http://www.zillow.com/zestimate/#acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats \n",
    "import sklearn as sk\n",
    "import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_plot\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.preprocessing import scale, StandardScaler\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Lars\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "#We are using the gmaps library to visualize on maps the homes by grid coordinates\n",
    "import gmaps\n",
    "key = 'AIzaSyAlll7ubMHP6cyZgX-ZLwWyd2KFKhEu_Hg'\n",
    "gmaps.configure(api_key=key)\n",
    "\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True) # one of the many color mappings\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "#configure the random seed so we our randomness is reproducible for selection of learn/test sets\n",
    "np.random.seed(0)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "\n",
    "HousePrices = pd.read_csv(\"Data/kc_house_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean the data (only removed one row)\n",
    "\n",
    "HousePrices = HousePrices[HousePrices['id']!=2402100895]\n",
    "\n",
    "HousePrices.index = range(21612)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create new variables\n",
    "\n",
    "# cleaned date\n",
    "HousePrices['date_year'] = HousePrices['date'].str[:4].astype(int)\n",
    "HousePrices['date_month'] = HousePrices['date'].apply(lambda x: x[4:6]).astype(int)\n",
    "HousePrices['date_day'] = HousePrices['date'].apply(lambda x: x[6:8]).astype(int)\n",
    "HousePrices['cleaned_date'] = pd.to_datetime(HousePrices['date_year']*10000 + \n",
    "                                             HousePrices['date_month']*100 + \n",
    "                                             HousePrices['date_day'], format = '%Y%m%d')\n",
    "# days since sale\n",
    "HousePrices['days_since_sale'] = pd.to_datetime(datetime.datetime.now().strftime(\"%Y-%m-%d\")) - HousePrices['cleaned_date']\n",
    "\n",
    "\n",
    "# property age\n",
    "HousePrices['property_age'] = pd.to_datetime(datetime.datetime.now().strftime(\"%Y-%m-%d\")).year - HousePrices['yr_built']\n",
    "\n",
    "# renovated indicator\n",
    "HousePrices['renovated_ind'] = np.where(HousePrices['yr_renovated'] ==0, 0,1)\n",
    "\n",
    "\n",
    "# renovated past 5 years\n",
    "pd.to_datetime(datetime.datetime.now().strftime(\"%Y-%m-%d\")).year - HousePrices['yr_renovated']\n",
    "\n",
    "HousePrices['yrs_since_reno'] = pd.to_datetime(datetime.datetime.now().strftime(\"%Y-%m-%d\")).year - HousePrices['yr_renovated']\n",
    "                                                \n",
    "HousePrices['renovated_past_5_years'] = np.where(np.logical_and(HousePrices['yrs_since_reno']>0, HousePrices['yrs_since_reno']<2017),1,0)\n",
    "del HousePrices['yrs_since_reno']\n",
    "\n",
    "# qualitative size grouping\n",
    "HousePrices['sqft_grouping'] = pd.cut(HousePrices.sqft_living, [0,1427,3300,5000,30000],4,\n",
    "                                      labels = ['Small','medium','large','McMansion'])\n",
    "\n",
    "# price per sqft\n",
    "HousePrices['price_sqft'] = HousePrices['price']/HousePrices['sqft_living']\n",
    "\n",
    "# large lot indicator\n",
    "HousePrices['large_lot_ind'] = np.where(HousePrices['sqft_lot'] >15000, 1,0)\n",
    "\n",
    "# bedroom/bathroom ratio\n",
    "HousePrices['bed_bath_ratio'] = HousePrices['bedrooms']/HousePrices['bathrooms']\n",
    "\n",
    "# sqft living ratio\n",
    "HousePrices['sqft_living_ratio'] = HousePrices['sqft_living']/HousePrices['sqft_living15']\n",
    "\n",
    "# property to lot ratio\n",
    "HousePrices['sqft_living_lot_ratio'] = HousePrices['sqft_living']/HousePrices['sqft_lot']\n",
    "\n",
    "# basement indicator\n",
    "HousePrices['basement_ind'] = np.where(HousePrices['sqft_basement'] ==0, 0,1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>days_since_sale</th>\n",
       "      <th>property_age</th>\n",
       "      <th>renovated_ind</th>\n",
       "      <th>renovated_past_5_years</th>\n",
       "      <th>price_sqft</th>\n",
       "      <th>large_lot_ind</th>\n",
       "      <th>bed_bath_ratio</th>\n",
       "      <th>sqft_living_ratio</th>\n",
       "      <th>sqft_living_lot_ratio</th>\n",
       "      <th>basement_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161200e+04</td>\n",
       "      <td>2.161200e+04</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>2.161200e+04</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21612</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>2.160500e+04</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "      <td>21612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580402e+09</td>\n",
       "      <td>5.400835e+05</td>\n",
       "      <td>3.369471</td>\n",
       "      <td>2.114774</td>\n",
       "      <td>2079.921016</td>\n",
       "      <td>1.510739e+04</td>\n",
       "      <td>1.494332</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234314</td>\n",
       "      <td>3.409356</td>\n",
       "      <td>...</td>\n",
       "      <td>843 days 19:13:33.548028</td>\n",
       "      <td>45.993753</td>\n",
       "      <td>0.042291</td>\n",
       "      <td>0.042291</td>\n",
       "      <td>264.150537</td>\n",
       "      <td>0.150148</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.052928</td>\n",
       "      <td>0.323747</td>\n",
       "      <td>0.392652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876594e+09</td>\n",
       "      <td>3.671351e+05</td>\n",
       "      <td>0.907982</td>\n",
       "      <td>0.770177</td>\n",
       "      <td>918.456818</td>\n",
       "      <td>4.142142e+04</td>\n",
       "      <td>0.539991</td>\n",
       "      <td>0.086519</td>\n",
       "      <td>0.766334</td>\n",
       "      <td>0.650668</td>\n",
       "      <td>...</td>\n",
       "      <td>113 days 01:08:12.541795</td>\n",
       "      <td>29.373636</td>\n",
       "      <td>0.201258</td>\n",
       "      <td>0.201258</td>\n",
       "      <td>110.059737</td>\n",
       "      <td>0.357225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.320451</td>\n",
       "      <td>0.268571</td>\n",
       "      <td>0.488352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>634 days 00:00:00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>87.588235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.179012</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.218375e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1426.500000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>733 days 00:00:00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.287533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.156576</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.619000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857 days 00:00:00</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>244.626805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.247641</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068825e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>943 days 00:00:00</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>318.321203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.160753</td>\n",
       "      <td>0.407563</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1024 days 00:00:00</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>810.138889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.653846</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161200e+04  2.161200e+04  21612.000000  21612.000000  21612.000000   \n",
       "mean   4.580402e+09  5.400835e+05      3.369471      2.114774   2079.921016   \n",
       "std    2.876594e+09  3.671351e+05      0.907982      0.770177    918.456818   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.218375e+05      3.000000      1.750000   1426.500000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     11.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161200e+04  21612.000000  21612.000000  21612.000000  21612.000000   \n",
       "mean   1.510739e+04      1.494332      0.007542      0.234314      3.409356   \n",
       "std    4.142142e+04      0.539991      0.086519      0.766334      0.650668   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.619000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068825e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "           ...                days_since_sale  property_age  renovated_ind  \\\n",
       "count      ...                          21612  21612.000000   21612.000000   \n",
       "mean       ...       843 days 19:13:33.548028     45.993753       0.042291   \n",
       "std        ...       113 days 01:08:12.541795     29.373636       0.201258   \n",
       "min        ...              634 days 00:00:00      2.000000       0.000000   \n",
       "25%        ...              733 days 00:00:00     20.000000       0.000000   \n",
       "50%        ...              857 days 00:00:00     42.000000       0.000000   \n",
       "75%        ...              943 days 00:00:00     66.000000       0.000000   \n",
       "max        ...             1024 days 00:00:00    117.000000       1.000000   \n",
       "\n",
       "       renovated_past_5_years    price_sqft  large_lot_ind  bed_bath_ratio  \\\n",
       "count            21612.000000  21612.000000   21612.000000    2.160500e+04   \n",
       "mean                 0.042291    264.150537       0.150148             inf   \n",
       "std                  0.201258    110.059737       0.357225             NaN   \n",
       "min                  0.000000     87.588235       0.000000    0.000000e+00   \n",
       "25%                  0.000000    182.287533       0.000000             NaN   \n",
       "50%                  0.000000    244.626805       0.000000             NaN   \n",
       "75%                  0.000000    318.321203       0.000000             NaN   \n",
       "max                  1.000000    810.138889       1.000000             inf   \n",
       "\n",
       "       sqft_living_ratio  sqft_living_lot_ratio  basement_ind  \n",
       "count       21612.000000           21612.000000  21612.000000  \n",
       "mean            1.052928               0.323747      0.392652  \n",
       "std             0.320451               0.268571      0.488352  \n",
       "min             0.179012               0.000610      0.000000  \n",
       "25%             0.881119               0.156576      0.000000  \n",
       "50%             1.000000               0.247641      0.000000  \n",
       "75%             1.160753               0.407563      1.000000  \n",
       "max             6.000000               4.653846      1.000000  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HousePrices.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create regression test and training sets\n",
    "\n",
    "del HousePrices['sqft_grouping'] # deleting since it is categorical, could use one hot coding\n",
    "del HousePrices['zipcode']\n",
    "del HousePrices['lat']\n",
    "del HousePrices['long']\n",
    "del HousePrices['days_since_sale']\n",
    "del HousePrices['cleaned_date']\n",
    "del HousePrices['bed_bath_ratio']\n",
    "\n",
    "y = HousePrices.ix[:,2]\n",
    "x = HousePrices.ix[:,3:36]\n",
    "\n",
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(x, y, test_size=  0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print (type(x_train), type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHuCAYAAAASiUFKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n48UGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116ff3f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlations just for reference:\n",
    "correlations = HousePrices.corr()\n",
    "ax = sns.heatmap(correlations, xticklabels = correlations.columns.values, yticklabels = correlations.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression (naive baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.49 MPE: 0.14 MAPE: 0.36 Median percent error: 0.06\n",
      "[ 16808.75788456] [ 0.]\n",
      "[ 281.1043067] -44316.3666324\n"
     ]
    }
   ],
   "source": [
    "# for this Naive model, we will only regress price and sqft_living and use this as a baseline\n",
    "\n",
    "# subsetting for x variables and setting values to arrays for the regression model\n",
    "\n",
    "x_train_model = np.array(x_train[['sqft_living']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.2f' %median_percent_error)\n",
    "\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "print(clf.coef_, clf.intercept_ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only explain 49% of the variation in home prices with this single variable and have an average error of 13% and an average absolute error of 36%.  We also have a significant p-value from this model.  As we can see, Zillow hides their inaccuracy by simply stating the median percent error rather than the average which is positively skewed.  We are doing well with this simple modeling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the correlation plot above, there are 10 features that may have a strong reltionship with price.  We will take a streamlined kitchen sink approach and throw these 10 variables into the x training set to see what this yields.  We expect a high degree of multi-collinearity based on the variables involved.  We selected variables based on the qualitative analysis that was previously completed on this dataset in hte previous project and the level of correlation of the variables with the overall price of the property.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.10 MAPE: 0.31 Median percent error: 0.048\n",
      "The f-statistics and p-values:  [ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n",
      "                   0    coefficient\n",
      "0        sqft_living     232.635797\n",
      "1           bedrooms  -30572.892298\n",
      "2          bathrooms  -14756.261295\n",
      "3           sqft_lot      -0.305263\n",
      "4               view   90804.278655\n",
      "5              grade   96068.339721\n",
      "6         sqft_above      96.124425\n",
      "7      sqft_basement     136.511372\n",
      "8      sqft_living15    -150.532027\n",
      "9  sqft_living_ratio -288302.723304\n"
     ]
    }
   ],
   "source": [
    "''' Before we get to the more complex regression models, we will try a \"best guess\" multiple regression model \n",
    "by simply adding in the variables that are most highly correlated with the home price '''\n",
    "\n",
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print('The f-statistics and p-values: ',f, pval, )\n",
    "\n",
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "\n",
    "\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the r-squared increased by 9 points and the MPE and MAPE showed some improvement.  However, we have to worry about over-fitting and the curse of dimensionality.  We did beat zillow's estimate of median error.  Although, we determined that this was a shady, smoke-in-mirrors stat.  Let's check out the VIF values to see what the multicollinearity looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PCA, we learned that orthogonal vectors are used to capture the variability within the dataset.  In the case of multicollinearity, we can transfer this knowledge to say that if there is no collinearity present, that we should see eigenvectors that are not close to zero.  \n",
    "reference : http://stackoverflow.com/questions/25676145/capturing-high-multi-collinearity-in-statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.72061312e+00   1.36527184e+00  -4.44494835e-16   3.53064049e-02\n",
      "   1.10022049e+00   9.83639858e-01   2.45556952e-01   3.35022509e-01\n",
      "   5.36886218e-01   6.77482600e-01]\n"
     ]
    }
   ],
   "source": [
    "correl_matrix = np.corrcoef(x_train_model, rowvar = 0)\n",
    "w, v = np.linalg.eig(correl_matrix) # create the eigen values and vectors\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although somewhat unbelievable, it appears that there is not much multicollinearity hear, which is somewhat doubtful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Since our dataset does not lend itself well to logistic regression (classification), we will interpret the standarized weights of the regression models instead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.10 MAPE: 0.31 Median percent error: 0.049\n",
      "                   0   coefficient\n",
      "0        sqft_living -1.345276e+17\n",
      "1           bedrooms -2.782400e+04\n",
      "2          bathrooms -1.139200e+04\n",
      "3           sqft_lot -1.303900e+04\n",
      "4               view  7.005200e+04\n",
      "5              grade  1.131720e+05\n",
      "6         sqft_above  1.211456e+17\n",
      "7      sqft_basement  6.459067e+16\n",
      "8      sqft_living15 -1.034720e+05\n",
      "9  sqft_living_ratio -9.287400e+04\n"
     ]
    }
   ],
   "source": [
    "# first we need to scale the x -variables with the standard scaler\n",
    "\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(x_train_model)\n",
    "\n",
    "x_train_model_scaled = scl_obj.transform(x_train_model)\n",
    "x_test_model_scaled = scl_obj.transform(x_test_model)\n",
    "\n",
    "# now, we will rerun the model with the standardized variables\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(x_train_model_scaled,y_train_model)\n",
    "\n",
    "clf.score(x_test_model_scaled, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model_scaled)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model_scaled, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "\n",
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "\n",
    "\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this model, we get the same accuracy, as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAHDCAYAAABFzjK0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCRJtf4/UYjGl9AJaecAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1178a76a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#ax=sns.barplot(y = a['coefficient'], x = a[0])\n",
    "\n",
    "weights = pd.Series(clf.coef_, index = list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "\n",
    "weights.plot(kind = 'bar')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To help in the interpretation of the standarized coefficients, we have plotted them on a bargraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **General takeaways**: It is apparent that the square footage of the living area is the variable that is most important in our prediction.  This makes perfect sense given the small amount of improvement that we saw in the regression with the additional variables.  It looks like the number of bedrooms, bathrooms, and the lot size play very little role in the overall price of the house and the regression model is not weighing these variables very highly.  It also looks like the square footage above if the next most important variable, followed by the square footage of the basement.  The only scary thing about this in the regression is that I would expect there to be multicollinearity.  However, based on the eigenvalues, this does not seem to be the case.  It appears that the squarefootage of the living area of houses within 15 miles is important as well as the ratio of the property to the closest 15 (would also expect multicollinearity).  \n",
    "\n",
    "* **sqft_living** : This continues to be the number one influential factor in our analysis.  We saw a strong linear relationship between this variable and price previously, but also noted that in a very generalized sense, the average price per square foot tends to decline slightly as the total square footage of the house increases.  In other words, we see a curved relationship and not a linear relationship between price per square foot and size.  There are other confounding variables at play that have some influence regrarding the retention of per square foot pricing as size increases.  \n",
    "\n",
    "* **bedrooms** : bedrooms appears the be very non-infuential in the overall weightings of the model.  This makes sense as we are already explaining variation in the size of the home and more than likely picking up bedrooms at a slower rate as square footage increases.  We can throw this variable out\n",
    "\n",
    "* **bathrooms** : The explanation for bathrooms is nearly the same as bedrooms.  The weights account for size via the overall square footage of the living area; therefore, the model does not put much weight into the total bathrooms of the property (despite the portional allocation of bathrooms required in King County).  \n",
    "\n",
    "* **sqft_lot** : Somewhat surprisingly, the squarefootage of the overall lot is of very little influence in the overall schema.  It would be amazing to see what a series of models based on data over the past 30 years for this variable would look like.  As a hunch, it seems that individuals purchasing homes are not as willing to pay a premium for more land to take care of.  In theory, this makes alot of sense due to a few considerations.  First, as society has become more sedentary due to tools such as computers, on-demand television, handheld devices, and other computing devices and software (Python ? :) ), people are less interested in spending time outdoors and would rather maximize time spent inside.  Additionally, millenials are having fewer children, later in life.  Perhaps these home buyers are less-concerned with having space for children to go outside and play and more concerned with amentities within the home.  Also, as society has continued to move back towards cities, sacrificing property size is part ofthe trade-off.  \n",
    "\n",
    "* **view** : View appears to be an important variable in the model as well.  Based on what we saw in our previous research, it is perfectly reasonable to expect that this plays an important role in the model.  Also notice that we did not choose to one-hot code this as a categorical variable.  We did this, because the magnitude of the value was influential in the value of the property. We may go back and code this later to see if we get any difference in models.\n",
    "\n",
    "* **grade**: Grade was another variable that could be one-hot coded. For the same reasons as view was not one-hot coded, we have not done that here.  Additionally, based on the previous research, it makes sense that the overall condition of the home contributes well to the overall price of the home and hence is weighted well in the model.  Remember, that in the previous analysis we noticed that the grading was generally equally influential at midpoint grades and above.  \n",
    "\n",
    "* **sqft_above** : This variable is important for the same reasons as the square footage of the living area.  We do worry a little bit that this is very close to the same thing as the total, but this seems to be an important piece of the model\n",
    "\n",
    "* **sqft_below** : The mere presence of a basement can often be an important piece of the puzzle.  This is the reason why we would assume that in addition to the square footage above, that this feature is important.  Also note, that one square foot above is worth more than a squarefoot in the basement.  It would be nice to have a feature that indicates whether the basement is finished or not.\n",
    "\n",
    "* **sqft_living15** : This is an interesting variable.  In general, this variable is important.  It makes sense that the size of the homes around a perticular property tends to be rather influential in the price of the home.  However, while we may not be required to look at the direction of the variable, it is important to note that this variable has a negative coefficient weight.  This is to say that as the square footage of homes around a target property go up, that the value of the target proprty declines.  This would notionally make sense if the property is smaller than those around it.  Unfortunately, we are not given more information about the properties included in this variable so it is a bit hard to determine if properties in urban areas are getting properties such as warehouses thrown into the equation.  This could be a relative influence factor and not necessarily an A to B translation.\n",
    "\n",
    "* **sqft_living_ratio** : To address the issue highlighted above, we created the sqft living ratio.  This ratio takes the square footage of the living area of the target property and divides by the average of the closest 15.  the inerpretation of this seems counter-intuitive.  While important for the model, we may want to try running it without this since we cannot necessarily fully explain what is going on here.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given what we observed above, we have decided to remove the sqft_living ratio, sqft_living15, bedrooms, bathrooms, and sqft_lot.  We will try rerunning the model with these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.58 MPE: 0.10 MAPE: 0.32 Median percent error: 0.043\n",
      "[ 16808.75788456   3409.4225623   13623.37345571  10069.772576\n",
      "   2033.82862905] [ 0.  0.  0.  0.  0.]\n",
      "               0   coefficient\n",
      "0    sqft_living -2.487239e+15\n",
      "1           view  9.592500e+04\n",
      "2          grade  9.723224e+04\n",
      "3     sqft_above  2.487239e+15\n",
      "4  sqft_basement  2.487239e+15\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','view','grade','sqft_above',\n",
    "                                  'sqft_basement']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','view','grade','sqft_above',\n",
    "                                  'sqft_basement']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval, )\n",
    "\n",
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','view','grade','sqft_above',\n",
    "                                  'sqft_basement']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, with 4 fewer variables, we actually get the same level of accuracy for MAPE and MPE.  Following Ocam's razor, this would be a better model to Fit.  Also, we beat Zillow's non-sense estimate by 40 basis points in this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the variable selection from above, we employed the RFE (Recursive Feature Elimination) algorithm from sklearn.  The algorithm employs a repeated method to remove the lowest weighted feature from the dataset.  In this case, we did not specify a value for the number of features to return, so the algorithm defaults to half of the original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        VariableName Support  Rank    Coefficient\n",
      "0        sqft_living    True     1     232.635797\n",
      "1           bedrooms   False     3  -30572.892298\n",
      "2          bathrooms   False     4  -14756.261295\n",
      "3           sqft_lot   False     6      -0.305263\n",
      "4               view    True     1   90804.278655\n",
      "5              grade    True     1   96068.339721\n",
      "6         sqft_above    True     1      96.124425\n",
      "7      sqft_basement    True     1     136.511372\n",
      "8      sqft_living15   False     5    -150.532027\n",
      "9  sqft_living_ratio   False     2 -288302.723304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57651217560203594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "selector = RFE(clf)\n",
    "selector = selector.fit(x_train_model, y_train_model)\n",
    "#print((selector.support_).reshape(selector.support_.shape[0],1))\n",
    "#print((selector.ranking_).reshape(selector.ranking_.shape[0],1))\n",
    "\n",
    "variables=pd.DataFrame(['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio'])\n",
    "#variables=variables.reshape(variables.shape[0],1)\n",
    "\n",
    "Support = pd.DataFrame(selector.support_.reshape(selector.support_.shape[0],1))\n",
    "Rank =  pd.DataFrame(selector.ranking_.reshape(selector.ranking_.shape[0],1))\n",
    "Coef = pd.DataFrame(clf.coef_.reshape(clf.coef_.shape[0],1))\n",
    "\n",
    "variables = pd.concat([variables, Support, Rank, Coef], axis=1)\n",
    "\n",
    "variables.columns=(['VariableName', 'Support', 'Rank', 'Coefficient'])\n",
    "print(variables)\n",
    "\n",
    "selector.score(x_test_model, y_test_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Recursive Feature Elimination recommends a regression based on a set of features including sqft_living, view, grade, sqft_above, and sqft_basement, with all selected factors having a positive coefficient.  Rerunning the model, with only these variables selected will allow us to evaluate the performance of the model with the automatically selected features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.90 MPE: -0.03 MAPE: 0.16 Median percent error: -0.018\n",
      "                         0    coefficient\n",
      "0                 bedrooms     715.311429\n",
      "1                bathrooms   14811.802854\n",
      "2              sqft_living     355.420991\n",
      "3                 sqft_lot      -0.133312\n",
      "4                   floors  -16336.502335\n",
      "5               waterfront  265818.608431\n",
      "6                     view   15079.788428\n",
      "7                condition   10209.107887\n",
      "8                    grade   20499.403478\n",
      "9               sqft_above     -16.317149\n",
      "10           sqft_basement     -36.395348\n",
      "11                yr_built   -1380.294738\n",
      "12            yr_renovated     277.672811\n",
      "13           sqft_living15     -78.253938\n",
      "14              sqft_lot15      -0.193989\n",
      "15               date_year    -611.618471\n",
      "16              date_month     -22.423916\n",
      "17                date_day      73.879305\n",
      "18            property_age   -1322.330082\n",
      "19           renovated_ind -526090.659193\n",
      "20  renovated_past_5_years      -0.000001\n",
      "21              price_sqft    1969.257124\n",
      "22           large_lot_ind    6440.076868\n",
      "23       sqft_living_ratio  -97747.853052\n",
      "24   sqft_living_lot_ratio  -14478.196509\n",
      "25            basement_ind   12486.543373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train)\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test)\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = Lasso( max_iter = 60000)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-values\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "#print(f, pval)\n",
    "\n",
    "a = pd.DataFrame(list(x_train))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.15311429e+02,   1.48118029e+04,   3.55420991e+02,\n",
       "        -1.33312025e-01,  -1.63365023e+04,   2.65818608e+05,\n",
       "         1.50797884e+04,   1.02091079e+04,   2.04994035e+04,\n",
       "        -1.63171488e+01,  -3.63953479e+01,  -1.38029474e+03,\n",
       "         2.77672811e+02,  -7.82539378e+01,  -1.93988577e-01,\n",
       "        -6.11618471e+02,  -2.24239163e+01,   7.38793052e+01,\n",
       "        -1.32233008e+03,  -5.26090659e+05,  -1.16552366e-06,\n",
       "         1.96925712e+03,   6.44007687e+03,  -9.77478531e+04,\n",
       "        -1.44781965e+04,   1.24865434e+04])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which attributes were selected?\n",
    "\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_ != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are very interesting.  We upped the max iterations to 60,000 in 10,000 increments  The LASSO regression did not throw out any variables and we threw every x-variable at the model.  We did fail to reach convergence.  We will try a couple of different approaches to see if we can get this to work.  Also, we will trim down the number of variables to the original multiple regression model and play with the 'tol' parameter to see if we are being too strict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.10 MAPE: 0.31 Median percent error: 0.048\n",
      "                   0    coefficient\n",
      "0        sqft_living     421.852523\n",
      "1           bedrooms  -30574.074935\n",
      "2          bathrooms  -14752.911377\n",
      "3           sqft_lot      -0.305263\n",
      "4               view   90803.002858\n",
      "5              grade   96065.302032\n",
      "6         sqft_above     -93.128574\n",
      "7      sqft_basement     -52.741906\n",
      "8      sqft_living15    -150.490767\n",
      "9  sqft_living_ratio -288227.590208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = Lasso( max_iter = 60000)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-values\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "#print(f, pval)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still failed to converge, but got back the same results as with the multple regression with more variables involved.  Maybe we could change the results by tweaking the tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.10 MAPE: 0.31 Median percent error: 0.048\n",
      "                   0    coefficient\n",
      "0        sqft_living     421.852523\n",
      "1           bedrooms  -30574.074935\n",
      "2          bathrooms  -14752.911377\n",
      "3           sqft_lot      -0.305263\n",
      "4               view   90803.002858\n",
      "5              grade   96065.302032\n",
      "6         sqft_above     -93.128574\n",
      "7      sqft_basement     -52.741906\n",
      "8      sqft_living15    -150.490767\n",
      "9  sqft_living_ratio -288227.590208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = Lasso( max_iter = 60000, tol = .001)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-values\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "#print(f, pval)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still get the same results.  We wonder if changing alpha to 0.5 (1 = linear regression) might help us get a different result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.10 MAPE: 0.31 Median percent error: 0.048\n",
      "                   0    coefficient\n",
      "0        sqft_living     421.974960\n",
      "1           bedrooms  -30573.483617\n",
      "2          bathrooms  -14754.586336\n",
      "3           sqft_lot      -0.305263\n",
      "4               view   90803.640756\n",
      "5              grade   96066.820877\n",
      "6         sqft_above     -93.232874\n",
      "7      sqft_basement     -52.846066\n",
      "8      sqft_living15    -150.511397\n",
      "9  sqft_living_ratio -288265.156756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = Lasso( max_iter = 60000, tol = .001, alpha = 0.5)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-values\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "#print(f, pval)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same results.  Let's move on from this one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LARS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.10 MAPE: 0.31 Median percent error: 0.048\n",
      "                   0    coefficient\n",
      "0        sqft_living     328.760222\n",
      "1           bedrooms  -30572.892298\n",
      "2          bathrooms  -14756.261295\n",
      "3           sqft_lot      -0.305263\n",
      "4               view   90804.278655\n",
      "5              grade   96068.339721\n",
      "6         sqft_above       0.000000\n",
      "7      sqft_basement      40.386947\n",
      "8      sqft_living15    -150.532027\n",
      "9  sqft_living_ratio -288302.723304\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = Lars(n_nonzero_coefs=np.inf)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-values\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "#print(f, pval)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LARS (Least Angle Regression) provides an identical R-squared value of 0.59 to LASSO, as well as matching on MPE, MAPE and Median Percent Error.  The coefficients found via this algorithm are also nearly identical to the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS regression with Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will next use principal component analysis, followed by a partial linear square regression to attempt to predict the price of a home.  For the principal component analysis, we have selected the continuous variables in the data set, including all of the square footage measures, as well as bedrooms, bathrooms, and floors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>3.333104e-01</td>\n",
       "      <td>4.246456e-01</td>\n",
       "      <td>2.524014e-01</td>\n",
       "      <td>0.475387</td>\n",
       "      <td>1.218242e-01</td>\n",
       "      <td>4.041223e-01</td>\n",
       "      <td>0.146647</td>\n",
       "      <td>0.449712</td>\n",
       "      <td>1.303049e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>1.415626e-01</td>\n",
       "      <td>1.262861e-01</td>\n",
       "      <td>1.524391e-01</td>\n",
       "      <td>0.038379</td>\n",
       "      <td>-6.844347e-01</td>\n",
       "      <td>2.853675e-03</td>\n",
       "      <td>0.057877</td>\n",
       "      <td>0.011760</td>\n",
       "      <td>-6.836330e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>floors</td>\n",
       "      <td>-2.369974e-01</td>\n",
       "      <td>9.779919e-03</td>\n",
       "      <td>5.657554e-01</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>7.257642e-03</td>\n",
       "      <td>-1.673673e-02</td>\n",
       "      <td>-0.738634</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>5.632119e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>-4.721720e-01</td>\n",
       "      <td>-2.706776e-01</td>\n",
       "      <td>-4.249412e-01</td>\n",
       "      <td>0.146880</td>\n",
       "      <td>-1.639883e-01</td>\n",
       "      <td>6.260186e-01</td>\n",
       "      <td>-0.141937</td>\n",
       "      <td>0.238780</td>\n",
       "      <td>-7.540046e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>7.277677e-01</td>\n",
       "      <td>-2.771295e-01</td>\n",
       "      <td>-3.824604e-01</td>\n",
       "      <td>-0.076118</td>\n",
       "      <td>-1.647415e-02</td>\n",
       "      <td>1.486706e-02</td>\n",
       "      <td>-0.463157</td>\n",
       "      <td>0.162413</td>\n",
       "      <td>-9.909440e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>-2.162321e-01</td>\n",
       "      <td>4.930012e-01</td>\n",
       "      <td>-4.573038e-01</td>\n",
       "      <td>0.136726</td>\n",
       "      <td>2.904984e-01</td>\n",
       "      <td>-4.045248e-01</td>\n",
       "      <td>-0.203980</td>\n",
       "      <td>0.260584</td>\n",
       "      <td>-3.533147e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>5.847161e-02</td>\n",
       "      <td>-4.218691e-01</td>\n",
       "      <td>2.302841e-01</td>\n",
       "      <td>0.075172</td>\n",
       "      <td>6.037427e-01</td>\n",
       "      <td>1.143524e-01</td>\n",
       "      <td>0.139970</td>\n",
       "      <td>0.008849</td>\n",
       "      <td>-6.022243e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>-9.964459e-02</td>\n",
       "      <td>-4.822255e-01</td>\n",
       "      <td>6.299379e-02</td>\n",
       "      <td>0.461253</td>\n",
       "      <td>-2.014874e-01</td>\n",
       "      <td>-5.172618e-01</td>\n",
       "      <td>0.144165</td>\n",
       "      <td>0.435340</td>\n",
       "      <td>1.494859e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>1.089352e-14</td>\n",
       "      <td>2.771164e-16</td>\n",
       "      <td>2.488930e-16</td>\n",
       "      <td>-0.699888</td>\n",
       "      <td>1.066441e-16</td>\n",
       "      <td>4.494509e-16</td>\n",
       "      <td>0.336037</td>\n",
       "      <td>0.630267</td>\n",
       "      <td>-5.386032e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label             0             1             2         3  \\\n",
       "0       bedrooms  3.333104e-01  4.246456e-01  2.524014e-01  0.475387   \n",
       "1      bathrooms  1.415626e-01  1.262861e-01  1.524391e-01  0.038379   \n",
       "2         floors -2.369974e-01  9.779919e-03  5.657554e-01 -0.135001   \n",
       "3    sqft_living -4.721720e-01 -2.706776e-01 -4.249412e-01  0.146880   \n",
       "4       sqft_lot  7.277677e-01 -2.771295e-01 -3.824604e-01 -0.076118   \n",
       "5  sqft_living15 -2.162321e-01  4.930012e-01 -4.573038e-01  0.136726   \n",
       "6  sqft_basement  5.847161e-02 -4.218691e-01  2.302841e-01  0.075172   \n",
       "7     sqft_above -9.964459e-02 -4.822255e-01  6.299379e-02  0.461253   \n",
       "8     sqft_lot15  1.089352e-14  2.771164e-16  2.488930e-16 -0.699888   \n",
       "\n",
       "              4             5         6         7             8  \n",
       "0  1.218242e-01  4.041223e-01  0.146647  0.449712  1.303049e-01  \n",
       "1 -6.844347e-01  2.853675e-03  0.057877  0.011760 -6.836330e-01  \n",
       "2  7.257642e-03 -1.673673e-02 -0.738634  0.243900  5.632119e-03  \n",
       "3 -1.639883e-01  6.260186e-01 -0.141937  0.238780 -7.540046e-02  \n",
       "4 -1.647415e-02  1.486706e-02 -0.463157  0.162413 -9.909440e-03  \n",
       "5  2.904984e-01 -4.045248e-01 -0.203980  0.260584 -3.533147e-01  \n",
       "6  6.037427e-01  1.143524e-01  0.139970  0.008849 -6.022243e-01  \n",
       "7 -2.014874e-01 -5.172618e-01  0.144165  0.435340  1.494859e-01  \n",
       "8  1.066441e-16  4.494509e-16  0.336037  0.630267 -5.386032e-17  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This section is heavily based off of the first project's PCA of Square footage only\n",
    "#PCA of the HousePrices to two principal components\n",
    "#First create a pandas dataframe of the different square footage measures, plus the three other\n",
    "#continuous measures\n",
    "Xpca=pd.DataFrame(scale(x_train[['bedrooms', 'bathrooms', 'floors',\n",
    "                                     'sqft_living', 'sqft_lot', 'sqft_living15', \n",
    "                                     'sqft_basement', 'sqft_above', 'sqft_lot15']]))\n",
    "\n",
    "#Perform a PCA of the HousePrices Data\n",
    "pca = PCA(n_components=9)\n",
    "X_pca = pca.fit(Xpca).transform(Xpca) # fit data and then transform it\n",
    "X_pca=pd.DataFrame(X_pca)\n",
    "Label=pd.DataFrame(['bedrooms', 'bathrooms', 'floors',\n",
    "                    'sqft_living', 'sqft_lot', 'sqft_living15',\n",
    "                    'sqft_basement', 'sqft_above', 'sqft_lot15'])\n",
    "\n",
    "Loadings=pd.DataFrame(pca.components_)\n",
    "Loadings.insert(0,'Label', value=Label)\n",
    "Loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loadings for the first principal component, labeled as 0 above, shows a heavy influence from the square feet of the lot, the square feet of the living space, as well as the number of bedrooms.  The second principal component contains a heavy influence based on the basement square footage, the square footage above group, and the bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.914430383742\n",
      "             PC\n",
      "0  4.423100e-01\n",
      "1  1.888590e-01\n",
      "2  1.539426e-01\n",
      "3  6.761594e-02\n",
      "4  6.170288e-02\n",
      "5  3.055577e-02\n",
      "6  2.908353e-02\n",
      "7  2.593032e-02\n",
      "8  1.211422e-29\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFoCAYAAADUycjgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIJS35angAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114663208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How much of the total variance of the six Square Footage statistics does our first 6 (0:5) PC's explain?\n",
    "print(sum(pca.explained_variance_ratio_[0:5]))\n",
    "pca2=pd.DataFrame(pca.explained_variance_ratio_)\n",
    "pca2=pca2.rename(columns = {0:'PC'})\n",
    "print(pca2)\n",
    "ax = pca2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scree plot reveals that 91% of the variance of the nine variables in the data set is explained via 6 principal components.  Our regression will be performed against principal components 0 through 5, representing a reduction in the space that the regression will be performed within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.52 MPE: 0.13 MAPE: 0.34 Median percent error: 0.058\n",
      "[  1928.13090294   6648.25538645   1240.1001983   16808.75788456\n",
      "    142.60901232   8798.11316151   2033.82862905  10069.772576\n",
      "    128.68913928] [  0.00000000e+000   0.00000000e+000   2.02228595e-262   0.00000000e+000\n",
      "   9.62788443e-033   0.00000000e+000   0.00000000e+000   0.00000000e+000\n",
      "   1.01034680e-029]\n"
     ]
    }
   ],
   "source": [
    "#Perform the regression on the PCA transformed variables\n",
    "\n",
    "#First subset the data\n",
    "x_train_model = np.array(scale(x_train[['bedrooms', 'bathrooms', 'floors',\n",
    "                                     'sqft_living', 'sqft_lot', 'sqft_living15', \n",
    "                                     'sqft_basement', 'sqft_above', 'sqft_lot15']]))\n",
    "\n",
    "#Transform the data with the PCA results, reducing from 9 variables to 6\n",
    "x_train_PCA = pca.transform(x_train_model)\n",
    "\n",
    "#\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit(x_train_PCA,y_train_model)\n",
    "\n",
    "#Transform the scaled x_test data to be fitted with the PCA\n",
    "x_test_model= pca.transform(scale(x_test[['bedrooms', 'bathrooms', 'floors',\n",
    "                                     'sqft_living', 'sqft_lot', 'sqft_living15', \n",
    "                                     'sqft_basement', 'sqft_above', 'sqft_lot15']]))\n",
    "\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With just the square foot variables and the bedrooms/bathrooms as principle components, the regression, while not as accurate as the simpler approaches still does pretty well.  It may also be a more objective representation of the data in a model, as only the most objective data fields - which can be reproduced easily in measurement - are included on the Principal component analysis and subsequent regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.74 MPE: 0.09 MAPE: 0.29 Median percent error: 0.015\n"
     ]
    }
   ],
   "source": [
    "# Now, let's try running a knn regression with the same variables as we had in the multiple regression\n",
    "\n",
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "# since this is KNN, we have to scale the variables first\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(x_train_model)\n",
    "\n",
    "x_train_model_scaled = scl_obj.transform(x_train_model)\n",
    "x_test_model_scaled = scl_obj.transform(x_test_model)\n",
    "\n",
    "# now, we will run the model with the standardized variables\n",
    "\n",
    "neighbors = 5\n",
    "\n",
    "clf = KNeighborsRegressor( n_neighbors = neighbors, metric = 'euclidean') # keeping 5 neighbors and using euclidean distance\n",
    "\n",
    "clf.fit(x_train_model_scaled,y_train_model)\n",
    "\n",
    "clf.score(x_test_model_scaled, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model_scaled)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_train_model_scaled, y_train_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the KNN regression, the R-squared increases to the highest level seen in this test.  However, we can see that any gains in average accuracy tend to be due to more equivalency in swings above and below zero.  The MAPE is about the same as we saw in the simple linear model to start.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.74 MPE: 0.09 MAPE: 0.29 Median percent error: 0.015\n"
     ]
    }
   ],
   "source": [
    "# change over to using standard Minkowski distance...you're not going to not test the distance named after the guy who taught Einstein...\n",
    "\n",
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "# since this is KNN, we have to scale the variables first\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(x_train_model)\n",
    "\n",
    "x_train_model_scaled = scl_obj.transform(x_train_model)\n",
    "x_test_model_scaled = scl_obj.transform(x_test_model)\n",
    "\n",
    "# now, we will run the model with the standardized variables\n",
    "\n",
    "neighbors = 5\n",
    "\n",
    "clf = KNeighborsRegressor( n_neighbors = neighbors, metric = 'minkowski') # keeping 5 neighbors and using euclidean distance\n",
    "\n",
    "clf.fit(x_train_model_scaled,y_train_model)\n",
    "\n",
    "clf.score(x_test_model_scaled, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model_scaled)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_train_model_scaled, y_train_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the distance type used to Minkowki gave the same exact results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.78 MPE: 0.09 MAPE: 0.30 Median percent error: 0.015\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "# since this is KNN, we have to scale the variables first\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(x_train_model)\n",
    "\n",
    "x_train_model_scaled = scl_obj.transform(x_train_model)\n",
    "x_test_model_scaled = scl_obj.transform(x_test_model)\n",
    "\n",
    "# now, we will run the model with the standardized variables\n",
    "\n",
    "neighbors = 3\n",
    "\n",
    "clf = KNeighborsRegressor( n_neighbors = neighbors, metric = 'minkowski') # keeping 5 neighbors and using euclidean distance\n",
    "\n",
    "clf.fit(x_train_model_scaled,y_train_model)\n",
    "\n",
    "clf.score(x_test_model_scaled, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model_scaled)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_train_model_scaled, y_train_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We played around with changing the neighbors around here a bit.  We found that, as expected, fewer neighbors tends to increase the r****2, but we tend to not gain much in the way of accuracy.  As we increase the size of the neighbors, we tend to increase the MAPE. Additionally, a lower number of neighbors allows us to game the z-estimate by making the median closer to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with RBF (Radial Basis Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -0.06 MPE: 0.11 MAPE: 0.42 Median percent error: 0.000\n"
     ]
    }
   ],
   "source": [
    "# we will now do an Support vector regression, RBF is the default and doesn't make much sense for this exercise\n",
    "\n",
    "# Let's start with a single variable\n",
    "\n",
    "x_train_model = np.array(x_train[['sqft_living']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'rbf')\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the support vector regression with Radial Basis resulted in a negative R-Squared value.  From the documentation for SVR (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) R-squared can be negative, but it shows that the model produces a consistently worse outcome than a constant prediction (R-squared of 0).\n",
    "\n",
    "Yes, we should NOT use this since it is not a radial basis problem.  We need to use a linear solution in this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SVR with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.46 MPE: 0.09 MAPE: 0.33 Median percent error: 0.007\n",
      "the support vectors are:  [[ 1350.]\n",
      " [ 3100.]\n",
      " [ 2160.]\n",
      " ..., \n",
      " [ 2360.]\n",
      " [ 2370.]\n",
      " [ 2380.]] the number of support vectors is:  17289\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'linear')\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print('the support vectors are: ', clf.support_vectors_,\n",
    "     'the number of support vectors is: ', len(clf.support_vectors_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this model to the simple linear regression, we actually have a lower R****2, but our mean percentage error is only 9% compared to 14% in the SLR.  Additionally, our MAPE is much improved by 3 percentage points.  Again...Median Percent Error...What this really shows is that our distribution of errors is probably much less positively skewed in this model than in the previous models (and Zillow's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 217.40890688]] [ 52117.30890687]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_, clf.intercept_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that with this model, we get a much more reasonable intercept (versus SLR) and a slightly lower coefficient to make up for it.  If nothing else, this model makes much more practical sense to explain to end-users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.46 MPE: 0.09 MAPE: 0.33 Median percent error: 0.007\n",
      "[ 16808.75788456] [ 0.]\n"
     ]
    }
   ],
   "source": [
    "# Let's change the value of hte regularization term C, the default is 1\n",
    "x_train_model = np.array(x_train[['sqft_living']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'linear', C = 50)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same variable, we get the same exact output with a C of 50, wonder what it looks like with a C of 100.  It may be worth mentioning that it is quite possible that we have essentially passed the plateau point in the gaints to be had.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.46 MPE: 0.09 MAPE: 0.33 Median percent error: 0.007\n",
      "[ 16808.75788456] [ 0.]\n"
     ]
    }
   ],
   "source": [
    "# Let's change the value of hte regularization term C, the default is 1\n",
    "x_train_model = np.array(x_train[['sqft_living']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'linear', C = 100)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we won't get any improvement by going higher, but could we still get the same results with a lower C?  It is worth noting that we get the same exact support vectors each time with this simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.46 MPE: 0.09 MAPE: 0.33 Median percent error: 0.007\n",
      "[ 16808.75788456] [ 0.]\n"
     ]
    }
   ],
   "source": [
    "# Let's change the value of hte regularization term C, the default is 1\n",
    "x_train_model = np.array(x_train[['sqft_living']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'linear', C = 10)\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like we can move on to multiple explanatory variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with linear kernel - multiple x-variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the starting point variables for the multiple regression for this problem and move from there as we fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.48 MPE: 0.08 MAPE: 0.32 Median percent error: 0.005\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "x_train_model = np.array(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'linear')\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This ran in slightly more than 9 minutes.  We need to run using the stochastic gradient descent in order to test the modeling parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.12326841e+02  -1.57406185e+03   1.24392857e+02  -1.90427162e-01\n",
      "    1.85615715e+03   3.59100024e+03   3.88995864e+01   7.34272542e+01\n",
      "    9.03825023e+01  -6.75720959e+01]] [-19965.60705173]\n"
     ]
    }
   ],
   "source": [
    "print(clf.coef_, clf.intercept_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in this model, the intercept is now less explainable (more on par with what we saw previously).  However, for the added run time that we got out of this model, we really didn't see as much improvement in our accuracy.  We are still slamming the Zillow numbers pretty good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0  coefficient\n",
      "0        sqft_living   112.326841\n",
      "1           bedrooms -1574.061846\n",
      "2          bathrooms   124.392857\n",
      "3           sqft_lot    -0.190427\n",
      "4               view  1856.157146\n",
      "5              grade  3591.000237\n",
      "6         sqft_above    38.899586\n",
      "7      sqft_basement    73.427254\n",
      "8      sqft_living15    90.382502\n",
      "9  sqft_living_ratio   -67.572096\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the low R squared of this model, the average accuracy is the best (on par with the multiple linear regression) we have seen given the linear model.  \n",
    "\n",
    "Since the solve from the standard optimization in the SVR takes so long to run for each iteration, we will look at the support vectors used to create the regression in this model, despite needing to use a stochastic approach to train several models and test parameters within a reasonable amount of time.  After we examine these support vectors, we will move on to testing the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17289"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vectors\n",
    "len(clf.support_vectors_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chosen Support Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17289"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# support vectors\n",
    "len(clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model chose to use every observation as a support vector to solve the problem.  We have to remember that support vectors are the data points that lie closest to the decision surface.  The decision surface is the hyperplane that separates classes.  In a sense, these are the datapoints that are the absolute hardest to classify (of course, we can make changes to this via increasing the value of the slack variable - shrinking C).  In this case, we have left the model at the default value of C=1. The output gave us a large number of support vectors.  Actually, each of the observations is a support vector.  This could be because we have too much slack in the model.  It could also be because the dataset is a very complex dataset for the model to solve.  As we increase the number of observations in the model and as we increase the number of features in the model, finding linear separable planes becomes harder and harder for the optimization problem  This could also explain the length of time needed to solve the problem.  If we potentially remove some slack, we may be shrink the support vector count, but we run the risk of overfitting due to the strictness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.47 MPE: 0.06 MAPE: 0.31 Median percent error: -0.012\n",
      "[ 946.9617519    90.60397972  441.33506079    8.15700389  179.41861221\n",
      "  871.43760764  683.97419198   47.84108109  599.44379417   76.70316032] [  9.07021020e-147   1.27502757e-020   2.00140918e-081   4.37847967e-003\n",
      "   9.55074514e-038   3.54707906e-138   3.01522666e-115   8.24565199e-012\n",
      "   4.68982809e-104   8.37898081e-018]\n"
     ]
    }
   ],
   "source": [
    "# try narrowing down the dataset to get a solution\n",
    "\n",
    "x_train_model = x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]\n",
    "\n",
    "x_train_model = np.array(x_train_model[:1000])\n",
    "\n",
    "y_train_model = np.array(y_train_model[:1000])\n",
    "\n",
    "x_test_model = np.array(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']])\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "clf = svm.SVR(kernel = 'linear')\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression(x_train_model, y_train_model)\n",
    "\n",
    "print(f, pval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that we re-ran with a much smaller dataset (and nice accuracy), let's see what the support vecotrs look like\n",
    "\n",
    "len(clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still selects every instance as a support vector.  We will move on to SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR with Stoachastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will next fit a regression with stoachastic gradient descent.  Based on a thread on StackOverflow (http://stackoverflow.com/questions/31443840/sgdregressor-nonsensical-result) we chose to scale (standardizing and centering) the X variables before fitting the linear regression.  Alpha, the regularization constant, has been set at 0.0001, the default for the package from SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.11 MAPE: 0.31 Median percent error: 0.054\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# here we will use the stochastic gradient descent on the set of classifiers to get better performance \n",
    "#and increase the number of runs that we can reasonably accomplish \n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 0.0001\n",
    "iterations= 100\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model provides one of the higher R-Squared values we've seen - at 0.58 - but slightly higher error measurements to most of the other models we've reviewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    coefficient\n",
      "0        sqft_living  159277.500180\n",
      "1           bedrooms  -30799.404871\n",
      "2          bathrooms  -13246.929892\n",
      "3           sqft_lot  -12155.179224\n",
      "4               view   65344.608570\n",
      "5              grade  111415.823784\n",
      "6         sqft_above  127484.349501\n",
      "7      sqft_basement   92630.283763\n",
      "8      sqft_living15 -103703.095204\n",
      "9  sqft_living_ratio  -94239.350318\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With the variables all standardized and centered, it becomes easier to see the variables with the largest impact - grade, the total square footage of living space, the square footage of living space, and the view.  When considering the scale of the coefficients - as the variables were standardized and centered - one standard deviation of additional square footage returns an additional $159,000 in sale value in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the next iteration of the model, we will increase the regularization constant, alpha to 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.58 MPE: 0.12 MAPE: 0.32 Median percent error: 0.065\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#Increase alpha to 0.1\n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 0.1\n",
    "iterations= 100\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing our value for alpha reduced the R-Squared, and increased two of the three measures for error in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0   coefficient\n",
      "0        sqft_living  86899.293106\n",
      "1           bedrooms -27270.969805\n",
      "2          bathrooms   3179.750616\n",
      "3           sqft_lot  -4760.914253\n",
      "4               view  71529.370005\n",
      "5              grade  96571.711610\n",
      "6         sqft_above  66434.008098\n",
      "7      sqft_basement  56388.419433\n",
      "8      sqft_living15   7746.983045\n",
      "9  sqft_living_ratio  -2044.639791\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the coefficients from the model with alpha = 0.1 reveals coefficients with larger absolute values for square feet of living space, grade, and square of living space above ground.  A review in detail may find the larger alpha value is leading to a generally higher estimate for the price of the home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.56 MPE: 0.14 MAPE: 0.32 Median percent error: 0.065\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "#Increase alpha to 0.5\n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 0.5\n",
    "iterations= 100\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0   coefficient\n",
      "0        sqft_living  54938.580958\n",
      "1           bedrooms  -8467.577006\n",
      "2          bathrooms  17590.849017\n",
      "3           sqft_lot  -3772.954051\n",
      "4               view  54206.106556\n",
      "5              grade  69476.614041\n",
      "6         sqft_above  42942.966716\n",
      "7      sqft_basement  33881.117687\n",
      "8      sqft_living15  36498.465748\n",
      "9  sqft_living_ratio  10573.568341\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shift to an alpha value = 0.5 has led to a much different set of coefficients, and higher error.  The coefficients in this case are a much more even weighting of the features of the regression model, without the disproportionate weighting that square feet of living space and view received in the earlier models with smaller alpha values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.54 MPE: 0.15 MAPE: 0.33 Median percent error: 0.074\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# CHANGE REG CONST TO 1.00\n",
    "\n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 1\n",
    "iterations= 100\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0   coefficient\n",
      "0        sqft_living  50944.762084\n",
      "1           bedrooms   2587.840174\n",
      "2          bathrooms  20068.110125\n",
      "3           sqft_lot   2659.377839\n",
      "4               view  39194.054658\n",
      "5              grade  54633.680996\n",
      "6         sqft_above  40873.523084\n",
      "7      sqft_basement  29444.332767\n",
      "8      sqft_living15  37749.035428\n",
      "9  sqft_living_ratio  13144.934387\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, with another increase in alpha value, this time to 1.0, we see a reduction in the range of values for the regression model and a more even distribution in the values of the coefficients.  \n",
    "\n",
    "Thus from our examples we've seen an increase in error measurements, and a decrease in R-Squared values from the larger value of alpha.  We will move in the opposite direction and decrease alpha and see if we can improve our performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.58 MPE: 0.13 MAPE: 0.32 Median percent error: 0.066\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# CHANGE REG CONST TO 0.00001\n",
    "\n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 0.000001\n",
    "iterations= 100\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alpha value of 0.000001 run over 100 iterations produced an R-squared of 0.59, a MPE of 0.11 and a MAPE of 0.32, with median percent error of 0.056.  This is a slight improvement over the default setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    coefficient\n",
      "0        sqft_living  153043.639049\n",
      "1           bedrooms  -33464.361398\n",
      "2          bathrooms  -17323.080204\n",
      "3           sqft_lot  -23512.698821\n",
      "4               view   73576.070269\n",
      "5              grade  110087.884246\n",
      "6         sqft_above  126433.969198\n",
      "7      sqft_basement   81616.657064\n",
      "8      sqft_living15 -107613.873263\n",
      "9  sqft_living_ratio  -99355.926014\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Again, the model sees the largest impact from changes in sqft_living, sqft_above, grade and sqft_basement. \n",
    "\n",
    "From the varied cases, we might hypothesize that the changing alpha value has the effect of moving from a model with heavy weighting on specific features to a model of more equal weighting between features, at least for the selected features in this model and data set.  This hypothesis might not hold true in other models.\n",
    "\n",
    "As a final test of the changes in parameters, we can test an increase by several orders of magnitude to learn if there is a difference in accuracy or construction of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.59 MPE: 0.12 MAPE: 0.31 Median percent error: 0.061\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# CHANGE REG CONST TO 0.00001, n=10,000\n",
    "\n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 0.000001\n",
    "iterations= 10000\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The higher number (10,000) iterations causes an improvement in Median percent error versus 100 iterations, while maintaining the same MPE and MAPE as lower number of iterations.  Is it even worth running 100 iterations, or does the model achieve the same performance at an n=10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    coefficient\n",
      "0        sqft_living  156749.380669\n",
      "1           bedrooms  -29035.415979\n",
      "2          bathrooms  -13564.752561\n",
      "3           sqft_lot  -13388.390378\n",
      "4               view   69101.253895\n",
      "5              grade  111277.650524\n",
      "6         sqft_above  128291.594648\n",
      "7      sqft_basement   85850.726921\n",
      "8      sqft_living15 -105654.757207\n",
      "9  sqft_living_ratio  -94138.582620\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.57 MPE: 0.09 MAPE: 0.34 Median percent error: 0.041\n",
      "[ 16808.75788456   1928.13090294   6648.25538645    142.60901232\n",
      "   3409.4225623   13623.37345571  10069.772576     2033.82862905\n",
      "   8798.11316151   1795.32408334] [  0.00000000e+00   0.00000000e+00   0.00000000e+00   9.62788443e-33\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# CHANGE REG CONST TO 0.00001, n=10\n",
    "\n",
    "scl = StandardScaler()\n",
    "x_train_model = np.array(scl.fit_transform(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_train_model = np.array(y_train)\n",
    "\n",
    "x_test_model = np.array(scl.fit_transform(x_test[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "y_test_model = np.array(y_test)\n",
    "\n",
    "regularize_const = 0.000001\n",
    "iterations= 10\n",
    "\n",
    "clf = SGDRegressor(loss = 'squared_loss', alpha  = regularize_const, n_iter=iterations, learning_rate='invscaling')\n",
    "\n",
    "\n",
    "clf.fit(x_train_model,y_train_model)\n",
    "\n",
    "clf.score(x_test_model, y_test_model)\n",
    "\n",
    "prediction = clf.predict(x_test_model)\n",
    "\n",
    "mean_percent_error = np.mean(prediction/y_test_model-1)\n",
    "\n",
    "mean_absolute_percent_error = np.mean(abs(prediction/y_test_model-1))\n",
    "\n",
    "median_percent_error = np.median(prediction/y_test_model-1)\n",
    "\n",
    "# check the R**2\n",
    "print('R-squared: %.2f' % clf.score(x_test_model, y_test_model), \n",
    "      'MPE: %.2f' % mean_percent_error, 'MAPE: %.2f' % mean_absolute_percent_error,\n",
    "     'Median percent error: %.3f' %median_percent_error)\n",
    "# look at the p-value\n",
    "\n",
    "f, pval = sk.feature_selection.f_regression((x_train_model), y_train_model)\n",
    "\n",
    "print(f, pval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower number of iterations does cause a degradation of performance, with a Median Percent Error of 0.062 and MPE of 0.13, versus 0.11 for 100 and 1000 iterations.  R-squared has also declined by 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0    coefficient\n",
      "0        sqft_living  166567.139511\n",
      "1           bedrooms  -22945.233677\n",
      "2          bathrooms   -3190.491000\n",
      "3           sqft_lot  -15639.615992\n",
      "4               view   65515.238053\n",
      "5              grade  118068.440920\n",
      "6         sqft_above  142344.057229\n",
      "7      sqft_basement   79942.217142\n",
      "8      sqft_living15  -93103.232647\n",
      "9  sqft_living_ratio  -87225.546904\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_train_model)\n",
    "\n",
    "a = pd.DataFrame(list(x_train[['sqft_living','bedrooms','bathrooms','sqft_lot','view','grade','sqft_above',\n",
    "                                  'sqft_basement','sqft_living15','sqft_living_ratio']]))\n",
    "b = pd.DataFrame(clf.coef_)\n",
    "\n",
    "#b = b.transpose()\n",
    "\n",
    "a['coefficient'] = b\n",
    "\n",
    "print (a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general construction and relationships of the coefficients is mostly unchanged, with Square feet of living, square feet above ground, and grade providing the largest changes in price per standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The models reviewed in this paper have produced mostly similar results, with R-squared varying from 0.49 to 0.90 based on the complexity of each model.  \n",
    "\n",
    "The measurement of MAPE has varied from 0.31 (several of the multiple regression models) to 0.36 for the simple linear regression based on square footage.  Zillow's choice of error measurement, Median Percent Error, ranged from 0.007 to 0.07.  \n",
    "The overall consistency of the coefficients for features between models, and the similar error rates between models may speak well to an ensemble approach, as discussed in many articles recently.\n",
    "\n",
    "In this case, we created over 10 models to forecast housing prices with methods as simple as simple linear regression to methods as complex as Support Vector regression using stochastic gradient descent.  In this exercise, we were not able to markedly improve the accuracy of the model by adding more complex/robust alrogithms to the mix.  Ultimately, the support vector regression did worse than the multiple regression as measured by mean percentage error and median percentage error.  Additionally, the MAPE stayed about the same.  \n",
    "\n",
    "One really surprising fact that we learned very early on in this paper was that the median percent error, which is used by Zillow, can infact be gamed by an analyst with the correct tools at hand.  For instance, if our objective function was simply to minimize the median percent error, we could just set the number of neighbors in a KNN algorithm very low and get a near perfect score.  While this approach does indeed myopically solve for a single value, it ignores the risks of over-fitting and the distribution of the errors inherent in something such as KNN.  If this exercise has taught us nothing else, it is that we need to be very careful when choosing accuracy measures, because they can be incredibly misleading.  If a certain model, by its nature, leads to more evenly distributed errors, then using something like a median could significantly impact results regardless of the swings that the forecast takes on either side of the results.  \n",
    "\n",
    "This project has also strengthened the need for remembering the principle of Occam's razor, which says that we should pick the simplest model that does the best job of predicting the final results.  As (aspiring) Data Scientists, we have to remember that the need for being able to transfer and explain models is still a very real part of the job.  If we can provide a forecast that is only half a point better than another, but it is 10 times more complex, we need to weigh the benefits of getting that additional accuracy.  In some cases, this may be necessary; however, in others, this additonal amount may be trivial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
